{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fststr import fststr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywrapfst as fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = []\n",
    "allomorphy = []\n",
    "with open(\"in_vocab_dictionary_verbs.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        lemma.append(line.split(',')[0])\n",
    "        allomorphy.append(line.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "rule = compiler.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(lemma)):\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    if len(allomorphy[index]) >= len(lemma[index]):\n",
    "        for i in range(len(allomorphy[index])):\n",
    "            if i < len(lemma[index]):\n",
    "                compiler.write(str(i) + ' ' + str(i+1) + ' ' + allomorphy[index][i] + ' ' + lemma[index][i] + '\\n')\n",
    "            else:\n",
    "                compiler.write(str(i) + ' ' + str(i+1) + ' ' + allomorphy[index][i] + ' <epsilon>' + '\\n')\n",
    "        l = len(allomorphy[index])\n",
    "        compiler.write(str(l) + ' ' + str(l+1) + ' <epsilon>' + ' +Known\\n')\n",
    "        compiler.write(str(l+1))\n",
    "        rule.union(compiler.compile())\n",
    "    else:\n",
    "        for i in range(len(lemma[index])):\n",
    "            if i < len(allomorphy[index]):\n",
    "                compiler.write(str(i) + ' ' + str(i+1) + ' ' + allomorphy[index][i] + ' ' + lemma[index][i] + '\\n')\n",
    "            else:\n",
    "                compiler.write(str(i) + ' ' + str(i+1) + ' <epsilon>' + ' ' + lemma[index][i] + '\\n')\n",
    "        l = len(lemma[index])\n",
    "        compiler.write(str(l) + ' ' + str(l+1) + ' <epsilon>' + ' +Known\\n')\n",
    "        compiler.write(str(l+1))\n",
    "        rule.union(compiler.compile())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(in_str):\n",
    "    out_set = set()\n",
    "    if in_str in allomorphy:\n",
    "        for i in fststr.apply(in_str, rule):\n",
    "            out_set.add(i)\n",
    "    return out_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delemmatize(in_str):\n",
    "    de_rule = rule.invert()\n",
    "    out_set = set()\n",
    "    if in_str[:-6] in lemma:\n",
    "        for i in fststr.apply(in_str, de_rule):\n",
    "            out_set.add(i)\n",
    "    return out_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lemmatizer:\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "\n",
    "    lemma = []\n",
    "    allomorphy = []\n",
    "\n",
    "    with open(\"in_vocab_dictionary_verbs.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            lemma.append(line.split(',')[0])\n",
    "            allomorphy.append(line.split(',')[1])\n",
    "\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    rule = compiler.compile()\n",
    "    \n",
    "    for index in range(len(lemma)):\n",
    "        compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "        if len(allomorphy[index]) >= len(lemma[index]):\n",
    "            for i in range(len(allomorphy[index])):\n",
    "                if i < len(lemma[index]):\n",
    "                    compiler.write(str(i) + ' ' + str(i+1) + ' ' + allomorphy[index][i] + ' ' + lemma[index][i] + '\\n')\n",
    "                else:\n",
    "                    compiler.write(str(i) + ' ' + str(i+1) + ' ' + allomorphy[index][i] + ' <epsilon>' + '\\n')\n",
    "            l = len(allomorphy[index])\n",
    "            compiler.write(str(l) + ' ' + str(l+1) + ' <epsilon>' + ' +Known\\n')\n",
    "            compiler.write(str(l+1))\n",
    "            rule.union(compiler.compile())\n",
    "        else:\n",
    "            for i in range(len(lemma[index])):\n",
    "                if i < len(allomorphy[index]):\n",
    "                    compiler.write(str(i) + ' ' + str(i+1) + ' ' + allomorphy[index][i] + ' ' + lemma[index][i] + '\\n')\n",
    "                else:\n",
    "                    compiler.write(str(i) + ' ' + str(i+1) + ' <epsilon>' + ' ' + lemma[index][i] + '\\n')\n",
    "            l = len(lemma[index])\n",
    "            compiler.write(str(l) + ' ' + str(l+1) + ' <epsilon>' + ' +Known\\n')\n",
    "            compiler.write(str(l+1))\n",
    "            rule.union(compiler.compile())\n",
    "    \n",
    "    de_rule = rule.copy().invert()\n",
    "    \n",
    "    def lemmatize(self, in_str):\n",
    "        out_set = set()\n",
    "        if in_str in self.allomorphy:\n",
    "            for i in fststr.apply(in_str, self.rule):\n",
    "                out_set.add(i)\n",
    "        return out_set\n",
    "\n",
    "    def delemmatize(self, in_str):\n",
    "        out_set = set()\n",
    "        if in_str[:-6] in self.lemma:\n",
    "            for i in fststr.apply(in_str, self.de_rule):\n",
    "                out_set.add(i)\n",
    "        return out_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fststr import fststr\n",
    "import pywrapfst as fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init FST\n",
    "def e_insertion():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    fst_file = open('e-insertion.txt').read()\n",
    "    print(fst_file, file=compiler)\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_insertion():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    fst_file = open('k-insertion.txt').read()\n",
    "    print(fst_file, file=compiler)\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_morphotactics():\n",
    "    suffix = ['', 's', 'ed', 'en', 'ing']\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    c = compiler.compile()\n",
    "    \n",
    "    for s in suffix:\n",
    "        compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "        compiler.write('0 0 <other> <other>\\n')\n",
    "        compiler.write('0 1 +Guess <^>\\n')\n",
    "        l = len(s)\n",
    "        for i in range(l):\n",
    "            compiler.write(str(i+1) + ' ' + str(i+2) + ' <epsilon> ' + s[i] + '\\n')\n",
    "        compiler.write(str(l+1) + ' ' + str(l+2) + ' <epsilon> <#>\\n')\n",
    "        compiler.write(str(l+2))\n",
    "        suffix_rule = compiler.compile()\n",
    "        c = c.union(suffix_rule)\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    compiler.write('0 0 <other> <other>\\n')\n",
    "    compiler.write('0 0 <#> <#>\\n')\n",
    "    compiler.write('0\\n')\n",
    "    # for special cases\n",
    "    compiler.write('0 1 <^> <epsilon>\\n')\n",
    "    compiler.write('1 0 <other> <other>\\n')\n",
    "    compiler.write('1 0 <#> <#>\\n')\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_deletion():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    fst_file = open('silent-e-deletion.txt').read()\n",
    "    print(fst_file, file=compiler)\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_sh_e_insertion():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    fst_file = open('ch_sh_e_insertion.txt').read()\n",
    "    print(fst_file, file=compiler)\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_replacement():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    fst_file = open('y_replacement.txt').read()\n",
    "    print(fst_file, file=compiler)\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_sharp():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    compiler.write('0\\n')\n",
    "    compiler.write('0 0 <other> <other>\\n')\n",
    "    compiler.write('0 1 <#> <epsilon>\\n')\n",
    "    compiler.write('1\\n')\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consonant_doubling():\n",
    "    st = fststr.symbols_table_from_alphabet(fststr.EN_SYMB)\n",
    "    compiler = fst.Compiler(isymbols=st, osymbols=st, keep_isymbols=True, keep_osymbols=True)\n",
    "    consonant = ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']\n",
    "    vowel = ['a', 'e', 'i', 'o', 'u']\n",
    "    compiler.write('0\\n')\n",
    "    compiler.write('0 0 <other> <other>\\n')\n",
    "    compiler.write('0 0 <#> <#>\\n')\n",
    "    for v in vowel:\n",
    "        compiler.write('0 2 ' + v + ' ' + v + '\\n')\n",
    "    for c in consonant:\n",
    "        compiler.write('0 1 ' + c + ' ' + c + '\\n')\n",
    "        compiler.write('1 1 ' + c + ' ' + c + '\\n')\n",
    "    for v in vowel:\n",
    "        compiler.write('1 2 ' + v + ' ' + v + '\\n')\n",
    "    compiler.write('2 2 i i\\n')\n",
    "    compiler.write('2 2 u u\\n')\n",
    "    for i in range(len(consonant)):\n",
    "        compiler.write('2 ' + str(i+3) + ' ' + consonant[i] + ' ' + consonant[i] + '\\n')\n",
    "        compiler.write(str(i+3) + ' ' + str(len(consonant)+3) + ' ' + '<^>' + ' ' + consonant[i] + '\\n')\n",
    "        compiler.write(str(i+3) + ' ' + str(len(consonant)+6) + ' ' + '<^>' + ' ' + consonant[i] + '\\n')\n",
    "        for c in consonant:\n",
    "            compiler.write(str(i+3) + ' 1 ' + c + ' ' + c + '\\n')\n",
    "        for v in vowel:\n",
    "            compiler.write(str(i+3) + ' 2 ' + v + ' ' + v + '\\n')\n",
    "    compiler.write(str(len(consonant)+3) + ' ' + str(len(consonant)+4) + ' e e' + '\\n')\n",
    "    compiler.write(str(len(consonant)+4) + ' ' + str(len(consonant)+5) + ' d d' + '\\n')\n",
    "    compiler.write(str(len(consonant)+5) + ' 0 <#> <#>' + '\\n')\n",
    "    compiler.write(str(len(consonant)+6) + ' ' + str(len(consonant)+7) + ' i i' + '\\n')\n",
    "    compiler.write(str(len(consonant)+7) + ' ' + str(len(consonant)+8) + ' n n' + '\\n')\n",
    "    compiler.write(str(len(consonant)+8) + ' ' + str(len(consonant)+5) + ' g g' + '\\n')\n",
    "    c = compiler.compile()\n",
    "    fststr.expand_other_symbols(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphotactics_rule = get_morphotactics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_insertion_rule = e_insertion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_insertion_rule = k_insertion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_deletion_rule = e_deletion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_rule = general()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_sh_e_insertion_rule = ch_sh_e_insertion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_replacement_rule = y_replacement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_sharp_rule = del_sharp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonant_doubling_rule = consonant_doubling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_rule = k_insertion_rule.union(e_insertion_rule).union(general_rule).union(e_deletion_rule).union(ch_sh_e_insertion_rule).union(y_replacement_rule).union(consonant_doubling_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = fst.compose(morphotactics_rule.arcsort(sort_type=\"olabel\"), new_rule.arcsort(sort_type=\"ilabel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rule = fst.compose(rule.arcsort(sort_type=\"olabel\"), del_sharp_rule.arcsort(sort_type=\"ilabel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_rule = final_rule.copy().invert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['squigging<#>']"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fststr.apply('squig<^>ing<#>', consonant_doubling_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bababbing<#>']"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fststr.apply('babab<^>ing<#>', consonant_doubling_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cccaccing<#>']"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fststr.apply('cccac<^>ing<#>', consonant_doubling_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rrrrunnuunning<#>']"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fststr.apply('rrrrunnuun<^>ing<#>', consonant_doubling_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbing<#>']"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fststr.apply('ab<^>ing<#>', consonant_doubling_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fus',\n",
       " 'fus',\n",
       " 'fuses',\n",
       " 'fuss',\n",
       " 'fuses',\n",
       " 'fuss',\n",
       " 'fused',\n",
       " 'fussed',\n",
       " 'fused',\n",
       " 'fussed',\n",
       " 'fusen',\n",
       " 'fusen',\n",
       " 'fusing',\n",
       " 'fussing',\n",
       " 'fusing',\n",
       " 'fussing']"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fststr.apply('fus+Guess', final_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
